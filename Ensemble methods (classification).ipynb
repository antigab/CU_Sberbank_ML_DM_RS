{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # отключаем предупреждения Anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.250</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.040</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.750</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.710</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "      <td>32.08</td>\n",
       "      <td>4.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>2.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>33.17</td>\n",
       "      <td>1.040</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>r</td>\n",
       "      <td>h</td>\n",
       "      <td>6.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>164.0</td>\n",
       "      <td>31285</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>22.92</td>\n",
       "      <td>11.585</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1349</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b</td>\n",
       "      <td>54.42</td>\n",
       "      <td>0.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>h</td>\n",
       "      <td>3.960</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>180.0</td>\n",
       "      <td>314</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b</td>\n",
       "      <td>42.50</td>\n",
       "      <td>4.915</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.165</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1442</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2      A3 A4 A5  A6 A7     A8 A9 A10  A11 A12 A13    A14    A15 A16\n",
       "0  b  30.83   0.000  u  g   w  v  1.250  t   t    1   f   g  202.0      0   +\n",
       "1  a  58.67   4.460  u  g   q  h  3.040  t   t    6   f   g   43.0    560   +\n",
       "2  a  24.50   0.500  u  g   q  h  1.500  t   f    0   f   g  280.0    824   +\n",
       "3  b  27.83   1.540  u  g   w  v  3.750  t   t    5   t   g  100.0      3   +\n",
       "4  b  20.17   5.625  u  g   w  v  1.710  t   f    0   f   s  120.0      0   +\n",
       "5  b  32.08   4.000  u  g   m  v  2.500  t   f    0   t   g  360.0      0   +\n",
       "6  b  33.17   1.040  u  g   r  h  6.500  t   f    0   t   g  164.0  31285   +\n",
       "7  a  22.92  11.585  u  g  cc  v  0.040  t   f    0   f   g   80.0   1349   +\n",
       "8  b  54.42   0.500  y  p   k  h  3.960  t   f    0   f   g  180.0    314   +\n",
       "9  b  42.50   4.915  y  p   w  v  3.165  t   f    0   t   g   52.0   1442   +"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные из файла 'crx.data.txt' с разделителем ',' и обозначением пропущенных значений '?'\n",
    "crx_data = pd.read_csv('crx.data.txt', sep=',', header=None, na_values='?')\n",
    "\n",
    "# назовем признаки так, как это указано в описании данных\n",
    "crx_data.columns = ['A'+str(i+1) for i in range(crx_data.shape[1])]\n",
    "crx_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# чтобы в дальнейшем не возникло проблем, преобразуем целочисленные переменные в действительные\n",
    "# (в описании данных указано, что A11 и A15 непрерывные, т.е. не категориальные, поэтому можем так сделать)\n",
    "crx_data[['A11', 'A15']] = crx_data[['A11', 'A15']].astype(float)\n",
    "crx_data.dropna(inplace=True)\n",
    "\n",
    "X = crx_data.iloc[:, :-1]\n",
    "\n",
    "y = crx_data.iloc[:, -1] # выделим целевую переменную (класс)\n",
    "\n",
    "\n",
    "# Преобразуем категориальные признаки (OneHotEnconding)\n",
    "# Каждому признаку с k уникальными значениями ставится в соответствие k-1 бинарный признак\n",
    "X = pd.get_dummies(X, prefix=[column for column in X.columns if X[column].dtype == object], drop_first=True)\n",
    "\n",
    "# Разделим на обучающую (70%) и тестовую выборки (30%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=10)\n",
    "\n",
    "# стандартизируем данные, чтобы по значению коэффициента переменной можно было судить о величине ее вклада в классификацию\n",
    "from sklearn.preprocessing import StandardScaler # вычитает среднее и делит на стандартное отклонение\n",
    "\n",
    "scaler_train = StandardScaler().fit(X_train) # оценим параметры стандартизации по обучающей выборке\n",
    "X_train = scaler_train.transform(X_train) # стандартизируем обучающую выборку\n",
    "X_test = scaler_train.transform(X_test) # стандартизируем тестовую выборку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценить преимущество ансамблевых классификаторов, возьмем в качестве baseline логистическую регрессию с параметрами, подобранными по кросс-валидации (смотри тетрадку по классификации), так как среди сравниваемых не ансамблевых классификаторов она показала наилучшие результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Свободный параметр: 0.395581705726\n",
      "Параметры: \n",
      "[[ -6.80209789e-02  -8.33302620e-02  -2.05838733e-01  -5.23075987e-01\n",
      "    1.54743590e-01  -4.05977241e-01  -5.84346291e-02  -6.02866395e-02\n",
      "    8.36491291e-02  -2.12043383e-01   8.36491291e-02  -4.03366066e-04\n",
      "   -9.30585688e-02  -4.34794729e-02  -1.95961402e-01   2.27212074e-01\n",
      "    1.80610278e-01   1.25492680e-01   1.55560166e-01   6.84127146e-03\n",
      "   -4.90835410e-02  -4.05124755e-02  -2.15960013e-01  -2.06507643e-01\n",
      "    3.76350785e-02   1.39310176e-01  -1.93717324e-01  -1.77599722e-01\n",
      "    4.12157959e-02   3.26498741e-02  -1.07976271e-01   2.73592974e-02\n",
      "   -1.26559175e+00  -2.98663749e-01   8.18393479e-02   0.00000000e+00\n",
      "    4.31966019e-02]]\n",
      "\n",
      "Число итераций: 50\n",
      "\n",
      "Accuracy на обучающей выборке: 0.8972\n",
      "Accuracy на тестовой выбоорке: 0.8469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "log_l2_clf = SGDClassifier(loss='log', penalty='l2', alpha=0.035, max_iter=10*5, \n",
    "                        n_jobs=4, random_state=0, learning_rate='optimal')\n",
    "\n",
    "log_l2_clf.fit(X_train_sc, y_train)\n",
    "\n",
    "print('Свободный параметр: {}'.format(log_l2_clf.intercept_[0]))\n",
    "print('Параметры: ')\n",
    "print(log_l2_clf.coef_)\n",
    "print('\\nЧисло итераций: {}\\n'.format(log_l2_clf.n_iter_))\n",
    "print('Accuracy на обучающей выборке: {:.4f}'.format(accuracy_score(y_train, log_l2_clf.predict(X_train_sc))))\n",
    "print('Accuracy на тестовой выбоорке: {:.4f}'.format(accuracy_score(y_test, log_l2_clf.predict(X_test_sc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "Различные варианты Bagging'а и соответствующие им значения параметров [BaggingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier) и [BaggingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor) в sklearn.\n",
    "\n",
    "* Pasting: случайные выборки объектов из имеющегося набора данных (0 < max_samples < 1.0, max_features=1.0, bootstrap=False)\n",
    "* Bagging: случаные выборки объектов с повторениями из имеющегося набора данных (0 < max_samples <= 1.0, max_features=1.0, bootstrap=True)\n",
    "* Random Subspaces: случайные выборки признаков (max_samples=1.0, 0 < max_features < 1.0, bootstrap=False)\n",
    "* Random Patches: случайные выборки объектов и признаков (0 < max_samples < 1.0, 0 < max_features < 1.0, boostrap=False или True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!! Внимание, следующий блок кода может должго выполняться. В классе его рекомендуется запустить с меньшими значениями max_iter и n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasting\n",
      "Accuracy на обучающей выборке: 0.8950\n",
      "Accuracy на тестовой выбоорке: 0.8367\n",
      "\n",
      "Bagging\n",
      "Accuracy на обучающей выборке: 0.9059\n",
      "Accuracy на тестовой выбоорке: 0.8418\n",
      "\n",
      "Random Subspaces\n",
      "Accuracy на обучающей выборке: 0.8906\n",
      "Accuracy на тестовой выбоорке: 0.8367\n",
      "\n",
      "Random Patches\n",
      "Accuracy на обучающей выборке: 0.8862\n",
      "Accuracy на тестовой выбоорке: 0.8214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# В качестве базового классификатора возьмем логистическую регрессию без регуляризации.\n",
    "# Берем без регуляризации, так как для bagging'a необходимы переобученные базовые модели,\n",
    "# т.е. модели высокой сложности.\n",
    "# Можно проверить, что с регуляризацией качество классификации ухудшится.\n",
    "base_classifier = SGDClassifier(loss='log', penalty='none', max_iter=10**5)\n",
    "\n",
    "# Pasting: обучаемся на 70% случайно выбранных объектах, повторяем 21 раз\n",
    "pasting = BaggingClassifier(base_classifier, max_samples=.7, max_features=1., bootstrap=False, \n",
    "                            n_estimators=21, n_jobs=4, random_state=0)\n",
    "\n",
    "# Bagging: обучаемся на 70% случаной выбранных объектах с возвращением, повторяем 21 раз\n",
    "bagging = BaggingClassifier(base_classifier, max_samples=.7, max_features=1., bootstrap=True, \n",
    "                            n_estimators=21, n_jobs=4, random_state=0)\n",
    "\n",
    "# Random Subspaces: обучаемся на 50% случано выбранных признаках, повторяем 21 раз\n",
    "random_subspaces = BaggingClassifier(base_classifier, max_samples=1., max_features=.5, bootstrap=False, \n",
    "                                     n_estimators=21, n_jobs=4, random_state=0)\n",
    "\n",
    "# Randomm Patches: обучаемся на 70% случайно выбранных объектов с возвращением и 70% случайно выбранных признаков,\n",
    "# повторяем 21 раз\n",
    "random_patches = BaggingClassifier(base_classifier, max_samples=.7, max_features=.7, bootstrap=True, \n",
    "                                   n_estimators=21, n_jobs=4, random_state=0)\n",
    "\n",
    "pasting.fit(X_train, y_train)\n",
    "bagging.fit(X_train, y_train)\n",
    "random_subspaces.fit(X_train, y_train)\n",
    "random_patches.fit(X_train, y_train)\n",
    "\n",
    "print('Pasting')\n",
    "print('Accuracy на обучающей выборке: {:.4f}'.format(accuracy_score(y_train, pasting.predict(X_train_sc))))\n",
    "print('Accuracy на тестовой выбоорке: {:.4f}'.format(accuracy_score(y_test, pasting.predict(X_test_sc))))\n",
    "\n",
    "print('\\nBagging')\n",
    "print('Accuracy на обучающей выборке: {:.4f}'.format(accuracy_score(y_train, bagging.predict(X_train_sc))))\n",
    "print('Accuracy на тестовой выбоорке: {:.4f}'.format(accuracy_score(y_test, bagging.predict(X_test_sc))))\n",
    "\n",
    "print('\\nRandom Subspaces')\n",
    "print('Accuracy на обучающей выборке: {:.4f}'.format(accuracy_score(y_train, random_subspaces.predict(X_train_sc))))\n",
    "print('Accuracy на тестовой выбоорке: {:.4f}'.format(accuracy_score(y_test, random_subspaces.predict(X_test_sc))))\n",
    "\n",
    "print('\\nRandom Patches')\n",
    "print('Accuracy на обучающей выборке: {:.4f}'.format(accuracy_score(y_train, random_patches.predict(X_train_sc))))\n",
    "print('Accuracy на тестовой выбоорке: {:.4f}'.format(accuracy_score(y_test, random_patches.predict(X_test_sc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из четырех вариантов лучшим оказался bagging, его и будем использовать в сравнении с другими ансамблями. При этом он превзошел по качеству логистическую регрессию на тестовой выборке. Разница в ошибке между обучающей и тестовой выборками также меньше, чем для логистической регресси, что, вообще говоря, тоже хороший знак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посомотреть, какие модели обучались в ансамбле. Например, первая модель в bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=100000, n_iter=None,\n",
       "       n_jobs=1, penalty='none', power_t=0.5, random_state=2087557356,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.estimators_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так можно увидеть номера объектов, которые попали в первую подвыборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   3,   4,   5,   9,  12,  16,  22,  24,  25,  26,  31,\n",
       "        32,  36,  38,  41,  44,  45,  49,  53,  55,  56,  57,  59,  60,\n",
       "        62,  64,  65,  66,  71,  73,  75,  76,  79,  80,  81,  84,  87,\n",
       "        88,  90,  91,  92,  93,  97,  98, 100, 101, 102, 103, 108, 109,\n",
       "       111, 114, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 128,\n",
       "       129, 133, 134, 135, 136, 137, 138, 139, 140, 143, 144, 146, 148,\n",
       "       150, 154, 156, 158, 159, 164, 165, 167, 169, 170, 171, 173, 174,\n",
       "       175, 176, 177, 183, 184, 186, 190, 192, 193, 194, 195, 197, 198,\n",
       "       201, 203, 206, 207, 213, 214, 215, 216, 218, 219, 220, 221, 224,\n",
       "       227, 229, 230, 232, 234, 235, 236, 237, 239, 240, 242, 245, 249,\n",
       "       251, 257, 259, 263, 265, 266, 269, 270, 272, 273, 276, 278, 279,\n",
       "       281, 282, 284, 286, 288, 289, 295, 301, 303, 304, 305, 310, 312,\n",
       "       315, 317, 323, 324, 325, 326, 330, 333, 335, 342, 345, 346, 347,\n",
       "       349, 351, 353, 358, 360, 361, 362, 365, 366, 367, 368, 370, 371,\n",
       "       373, 374, 375, 376, 377, 378, 381, 382, 383, 384, 386, 388, 390,\n",
       "       395, 396, 398, 403, 404, 406, 407, 410, 411, 415, 416, 417, 418,\n",
       "       420, 422, 423, 425, 431, 432, 433, 434, 435, 443, 444, 448, 450,\n",
       "       453, 454, 456], dtype=int64)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(X_train.shape[0])[bagging.estimators_samples_[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А так увидеть номера признаков, которые использовались для обучения первой модели в ансамбле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36], dtype=int64)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(X_test.shape[0])[bagging.estimators_features_[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также для большинства классификаторов и ансамблевых методов доступна опция warm_start=True, которая при наличии новой порции данных для обучения \"дообучает\" модель. Ниже исключительно в целях демонтсрации приведен пример, как это сделать в случае с Bagging'ом. Для других моделей аналогично. Это полезно делать, если данные большие или поступают постепенно и нет возможности хранить их целиком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy на обучающей выборке: 0.8884\n",
      "Accuracy на тестовой выбоорке: 0.7551\n"
     ]
    }
   ],
   "source": [
    "# обратите внимание на параметр warm_start=True, иначе не на новой порции данных модель будет обучаться с 0.\n",
    "bagging_warm = BaggingClassifier(base_classifier, max_samples=.7, max_features=1., bootstrap=True, \n",
    "                                 n_estimators=11, n_jobs=4, random_state=0, warm_start=True)\n",
    "\n",
    "X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, y_train, test_size=.5)\n",
    "\n",
    "# Предположим, что сначала нам была доступна только половина данных для обучения (X_train1, y_train1) и мы обучаем модель\n",
    "bagging_warm.fit(X_train1, y_train1)\n",
    "# После получения второй части данных для обучения, мы уточняем уже обученную модель\n",
    "bagging_warm.fit(X_train2, y_train2)\n",
    "\n",
    "print('Accuracy на обучающей выборке: {:.4f}'.format(accuracy_score(y_train, bagging_warm.predict(X_train_sc))))\n",
    "print('Accuracy на тестовой выбоорке: {:.4f}'.format(accuracy_score(y_test, bagging_warm.predict(X_test_sc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайный лес\n",
    "\n",
    "В scikit-learn есть две реализации случайного леса. Разница заключается в том, как выбираются пороговые значения признаков.\n",
    "\n",
    "[RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) на каждом шаге просматривает все пороговые значения каждого признака из случайно выбранного подмножества признаков и выбирает признак и порог для него, которые обеспечивают наилучшее на данном шаге разбиение. \n",
    "\n",
    "[ExtraTreesClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier) для каждого признака из случайного подмножества признаков выбирает случайный порог, а затем выбирает признак, случайны порог которого обеспечил лучшее разбиение на текущем шаге.\n",
    "\n",
    "Также для обоих подходов существуют реализации для задачи регрессии: [RandomForestRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor) и [ExtraTreesRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy на обучающей выборке: 0.9300\n",
      "Accuracy на тестовой выбоорке: 0.8673\n",
      "\n",
      "Важность признаков: \n",
      "A2: 0.0275\n",
      "A3: 0.0375\n",
      "A8: 0.0951\n",
      "A11: 0.1427\n",
      "A14: 0.0334\n",
      "A15: 0.0864\n",
      "A1_b: 0.0022\n",
      "A4_u: 0.0051\n",
      "A4_y: 0.0051\n",
      "A5_gg: 0.0026\n",
      "A5_p: 0.0057\n",
      "A6_c: 0.0023\n",
      "A6_cc: 0.0020\n",
      "A6_d: 0.0015\n",
      "A6_e: 0.0020\n",
      "A6_ff: 0.0100\n",
      "A6_i: 0.0053\n",
      "A6_j: 0.0006\n",
      "A6_k: 0.0064\n",
      "A6_m: 0.0013\n",
      "A6_q: 0.0049\n",
      "A6_r: 0.0000\n",
      "A6_w: 0.0081\n",
      "A6_x: 0.0075\n",
      "A7_dd: 0.0007\n",
      "A7_ff: 0.0084\n",
      "A7_h: 0.0128\n",
      "A7_j: 0.0028\n",
      "A7_n: 0.0002\n",
      "A7_o: 0.0000\n",
      "A7_v: 0.0021\n",
      "A7_z: 0.0007\n",
      "A9_t: 0.3823\n",
      "A10_t: 0.0869\n",
      "A12_t: 0.0036\n",
      "A13_p: 0.0000\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=1000, criterion='gini', max_features='sqrt', \n",
    "                                       n_jobs=4, random_state=0, bootstrap=True, max_depth=10, \n",
    "                                       min_samples_split=30)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy на обучающей выборке: {:.4f}'.format(accuracy_score(y_train, random_forest.predict(X_train_sc))))\n",
    "print('Accuracy на тестовой выбоорке: {:.4f}'.format(accuracy_score(y_test, random_forest.predict(X_test_sc))))\n",
    "\n",
    "# Случайные леса, в том числе, осуществляют оценку важности признаков\n",
    "print('\\nВажность признаков: ')\n",
    "for i, c in enumerate(X.columns[:-1]):\n",
    "    print(c + ': ' + '%.4f' % random_forest.feature_importances_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest c выбранными параметрами оказался лучше, чем Bagging. Самым важным признаком RandomForest считает признак A9==t, второй по важности A11. Оценку важности признаков, полученную при помощи случайного леса можно использовать в качестве весов для других классификаторов или для отбора признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно посомтреть, какие модели обучались в ансамбле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=30,\n",
       "            min_weight_fraction_leaf=0.0, presort=False,\n",
       "            random_state=209652396, splitter='best')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.estimators_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все то же самое для ExtraTreesClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy на обучающей выборке: 1.0000\n",
      "Accuracy на тестовой выбоорке: 0.8724\n",
      "\n",
      "Важность признаков: \n",
      "A2: 0.0443\n",
      "A3: 0.0446\n",
      "A8: 0.0550\n",
      "A11: 0.0497\n",
      "A14: 0.0435\n",
      "A15: 0.0354\n"
     ]
    }
   ],
   "source": [
    "extra_trees = ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_features='sqrt', \n",
    "                                   n_jobs=4, random_state=0, class_weight='balanced', bootstrap=True)\n",
    "\n",
    "extra_trees.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy на обучающей выборке: {:.4f}'.format(accuracy_score(y_train, extra_trees.predict(X_train_sc))))\n",
    "print('Accuracy на тестовой выбоорке: {:.4f}'.format(accuracy_score(y_test, extra_trees.predict(X_test_sc))))\n",
    "print('\\nВажность признаков: ')\n",
    "for i, c in enumerate(X.columns[:-1]):\n",
    "    print(c + ': ' + '%.4f' % extra_trees.feature_importances_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExtraTreesCalssifier с выбранными параметрами по доле верных предсказаний превосходит все другие обученные ранее классификаторы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html#sphx-glr-auto-examples-ensemble-plot-ensemble-oob-py Здесь можно посмотреть, как построить графики того, как изменяется ошибка предсказания с ростом числа деревьев в случайном лече."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бустинг в scikit-learn представлен двумя подходами [AdaBoostClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier) и [GradientBoostingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier). Есть также версии для задачи регрессии: [AdaBoostRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor) и [GradientBoostingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor).\n",
    "\n",
    "Важно помнить, что в отличие от Bagging'а в качестве базового классификатора для AdaBoost необходимо брать модели низкой сложности. Например, деревья глубины 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_boost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), \n",
    "                               n_estimators=1000, learning_rate=.1, \n",
    "                               algorithm='SAMME', random_state=0)\n",
    "\n",
    "ada_boost.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy на обучающей выборке: {:.4f}'.format(accuracy_score(y_train, ada_boost.predict(X_train_sc))))\n",
    "print('Accuracy на тестовой выбоорке: {:.4f}'.format(accuracy_score(y_test, ada_boost.predict(X_test_sc))))\n",
    "print('\\nВажность признаков: ')\n",
    "for i, c in enumerate(X.columns[:-1]):\n",
    "    print(c + ': ' + '%.4f' % ada_boost.feature_importances_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля верных предсказаний выше, чем у логистической регрессии, но ниже чем у ExtraTreesClassifier.\n",
    "\n",
    "В отличие от случайных лесов самым важным признаком оказался признак A15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посомтреть на веса классификаторов, добавляемых на каждом шаге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(ada_boost.estimator_weights_)), ada_boost.estimator_weights_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А так же на ошибку классификации каждого нового классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(ada_boost.estimator_errors_)), ada_boost.estimator_errors_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем обучить градиентный бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(loss='deviance', learning_rate=.01, n_estimators=1000, \n",
    "                                               max_depth=1, subsample=.6, max_features=None, random_state=0)\n",
    "\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy на обучающей выборке: {:.4f}'.format(accuracy_score(y_train, gradient_boosting.predict(X_train_sc))))\n",
    "print('Accuracy на тестовой выбоорке: {:.4f}'.format(accuracy_score(y_test, gradient_boosting.predict(X_test_sc))))\n",
    "print('\\nВажность признаков: ')\n",
    "for i, c in enumerate(X.columns[:-1]):\n",
    "    print(c + ': ' + '%.4f' % gradient_boosting.feature_importances_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество выше, чем у логистической регрессии, но ниже чем у чемпиона. Признаки A9_t и A14 посчитал самыми важными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно изобразить на графике, на сколько уменьшалась ошибка при добавлении нового классификатора на каждом шаге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(gradient_boosting.oob_improvement_)), gradient_boosting.oob_improvement_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А также, как снижалось значение ошибки на обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(gradient_boosting.train_score_)), gradient_boosting.train_score_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Голосование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один вариант ансамбля, предназнначенный для задачи классификации - голосование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# выберем 5 классификаторов\n",
    "clf1 = SGDClassifier(loss='log', penalty='l2', alpha=0.035, max_iter=10000, random_state=100, n_jobs=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=48, weights='distance', n_jobs=4)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = SVC(C=0.87, kernel='sigmoid', probability=True, random_state=0)\n",
    "clf5 = DecisionTreeClassifier(criterion='gini', max_depth=7, max_features='sqrt', min_samples_split=23, \n",
    "                              splitter='random', random_state=0)\n",
    "\n",
    "# финальное предсказание будем делать путем голосования с весами классификаторов (weights)\n",
    "voting = VotingClassifier(estimators=[('log', clf1), ('knn', clf2), ('nb', clf3), ('svm', clf4), ('dt', clf5)],\n",
    "                          weights=[1, 1, 1, 1, 10], voting='soft', n_jobs=4)\n",
    "\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy на обучающей выборке: {:.4f}'.format(accuracy_score(y_train, voting.predict(X_train_sc))))\n",
    "print('Accuracy на тестовой выбоорке: {:.4f}'.format(accuracy_score(y_test, voting.predict(X_test_sc))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нам необходимо оценить качество классификации не для одного класса, а для всех классов в среднем, для таких мер как precision, recall, f1-мера и auc применяются различный процедуры усреднения (см. памятку по multiclass classification).\n",
    "\n",
    "Здесь воспользуемся двумя стратегиями усреднения: micro и macro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, precision_score, recall_score\n",
    "\n",
    "predictions = {'Logistic Regression': log_l2_clf.predict(X_test),\n",
    "               'Bagging': bagging.predict(X_test),\n",
    "               'AdaBoost': ada_boost.predict(X_test),\n",
    "               'GradientBoosting': gradient_boosting.predict(X_test),\n",
    "               'Random Forest': random_forest.predict(X_test),\n",
    "               'Extra Trees': extra_trees.predict(X_test),\n",
    "               'Voting': voting.predict(X_test)\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Precision: ')\n",
    "for model in predictions:\n",
    "    print('\\t' + model + ': micro %.4f' % precision_score(y_test, predictions[model], average='micro') + \n",
    "          ': macro %.4f' % precision_score(y_test, predictions[model], average='macro'))\n",
    "    \n",
    "print('Recall: ')\n",
    "for model in predictions:\n",
    "    print('\\t' + model + ': micro %.4f' % recall_score(y_test, predictions[model], average='micro') + \n",
    "          ': macro %.4f' % recall_score(y_test, predictions[model], average='macro'))\n",
    "    \n",
    "print('F1-score: ')\n",
    "for model in predictions:\n",
    "    print('\\t' + model + ': micro %.4f' % f1_score(y_test, predictions[model], average='micro') + \n",
    "          ': macro %.4f' % f1_score(y_test, predictions[model], average='macro'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценки micro и macro одной и той же меры качества для одного и того же классификатора мало отличаются. Глядя на результаты можно заключить, что несомтря на то, что по доле верных предсказаний ансамблевые методы не сильно превосходили логистическую регрессию, то при усреднении по двум классам значения мер precision, recall и f1-мера для ансамблей значительно превосходят соответствующие значения для логистической регресии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки усредненного AUC необходимы предсказания вероятностей для каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "probabilities = {'Logistic Regression': log_l2_clf.predict_proba(X_test),\n",
    "                 'Bagging': bagging.predict_proba(X_test),\n",
    "                 'AdaBoost': ada_boost.predict_proba(X_test),\n",
    "                 'GradientBoosting': gradient_boosting.predict_proba(X_test),\n",
    "                 'Random Forest': random_forest.predict_proba(X_test),\n",
    "                 'Extra Trees': extra_trees.predict_proba(X_test),\n",
    "                }\n",
    "\n",
    "# для оценки roc_auc_score, усредненной по всем классам, необходимо целевую переменную представить \n",
    "# в виде набора бинарных переменных\n",
    "# например, y = ['+', '-', '+'] -> [[1, 0], [0, 1], [1, 0]], если первый столбец соответствует метке '+', а второй - метке '-'\n",
    "# для этого используется MultiLabelBinarizer\n",
    "\n",
    "# чтобы столбцы с одинаковым номером в матрицах классов и вероятностей соответствовали одной и той же метке класса,\n",
    "# на вход MultiLabelBinariazer необходимо подать метки классов в необходимом порядке.\n",
    "# для обученных классификаторов эту информацию можно получить через .classes_\n",
    "binary_classes = {'Logistic Regression': MultiLabelBinarizer(log_l2_clf.classes_).fit_transform(y_test),\n",
    "                   'Bagging': MultiLabelBinarizer(bagging.classes_).fit_transform(y_test),\n",
    "                   'AdaBoost': MultiLabelBinarizer(ada_boost.classes_).fit_transform(y_test),\n",
    "                   'GradientBoosting': MultiLabelBinarizer(gradient_boosting.classes_).fit_transform(y_test),\n",
    "                   'Random Forest': MultiLabelBinarizer(random_forest.classes_).fit_transform(y_test),\n",
    "                   'Extra Trees': MultiLabelBinarizer(extra_trees.classes_).fit_transform(y_test),\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('AUC: ')\n",
    "for model in probabilities:\n",
    "    print('\\t' + model + ': micro %.4f' % roc_auc_score(binary_classes[model], probabilities[model], average='micro') + \n",
    "          ': macro %.4f' % roc_auc_score(binary_classes[model], probabilities[model], average='macro'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среднее знначение AUC для GradientBoosting оказывается максимальным, хотя по остальным мерам лидировал ExtraTreesClassifier. Вероятно, изменив порог вероятности принадлежности классам можно увеличить точность предсказания градиентного бустинга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой тетрадке не представлен выбор оптимальных параметров для ансамблей. Это можно сделать также, как и для классификаторов посредством GridSearchCV, о котором шла речь в тетрадке по классификации.\n",
    "\n",
    "Также можно оценивать качесво ансамблей на кросс-валидации (см. по аналогии с классификацией)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
